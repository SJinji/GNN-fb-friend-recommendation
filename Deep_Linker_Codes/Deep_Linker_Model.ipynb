{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sUpBpD9v0LIX"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from utils_new import *\n",
        "from models import GAT\n",
        "import _pickle as pickle\n",
        "#from load_karate import load_karate\n",
        "from sample_new import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy.core.numeric as _nx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bgJ-PerwSFI",
        "outputId": "0f911c09-ad5c-4100-a6ac-41c0975780d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Arguments object at 0x7fd509196e50>\n"
          ]
        }
      ],
      "source": [
        "# training settings\n",
        "class Arguments():\n",
        "  def __init__(self, cuda=True, fastmode=False, seed=42, epochs=100,\n",
        "              lr=4e-4, weight_decay=5e-4, hidden=32, K=6, dropout=0.1, \n",
        "               batchSize=32, testBatchSize=32,\n",
        "               sampleSize='20,20', breakPortion=0.2, patience=\"Patience\", trainAttention=True):\n",
        "\n",
        "    self.cuda = cuda\n",
        "    self.K = K\n",
        "    self.fastmode = fastmode\n",
        "    self.seed = seed\n",
        "    self.epochs = epochs\n",
        "    self.lr = lr\n",
        "    self.weight_decay = weight_decay\n",
        "    self.hidden = hidden\n",
        "    self.dropout = dropout\n",
        "    self.batchSize = batchSize\n",
        "    self.testBatchSize = testBatchSize\n",
        "    self.sampleSize = sampleSize\n",
        "    self.breakPortion = breakPortion\n",
        "    self.patience = patience\n",
        "    self.trainAttention = trainAttention\n",
        "\n",
        "args = Arguments()\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Ss455LzIyT",
        "outputId": "594712f8-348b-4f7d-82ab-43725e5eec95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train negative sampling done\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# Load data\n",
        "ori_adj, adj, features, idx_train, idx_val, idx_test = load_project_data(args.breakPortion)\n",
        "\n",
        "# set val set equivalent to test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jMd8yLO44ivR"
      },
      "outputs": [],
      "source": [
        "node_num = features.numpy().shape[0]\n",
        "sampleSize = list(map(int, args.sampleSize.split(',')))\n",
        "\n",
        "# model configuration \n",
        "model = GAT(K = 6, node_num = features.numpy().shape[0],nfeat=features.numpy().shape[1],nhid=args.hidden,nclass=2,sampleSize = sampleSize, dropout=args.dropout,trainAttention=args.trainAttention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hWumcuYzVuO",
        "outputId": "e3d84af7-6557-4e70-e10f-11c4ab0c31b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only use one GPU\n"
          ]
        }
      ],
      "source": [
        "# set optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use multi-GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "else:\n",
        "    print(\"Only use one GPU\")\n",
        "\n",
        "labels = adj.view(node_num*node_num).type_as(idx_train)\n",
        "labels = labels.type(torch.FloatTensor)\n",
        "ori_labels = ori_adj.view(node_num*node_num).type_as(idx_train)\n",
        "ori_labels = ori_labels.type(torch.FloatTensor)\n",
        "criterion = nn.BCELoss() \n",
        "adj,ori_labels = Variable(adj), Variable(ori_labels) \n",
        "features = Variable(features)\n",
        "labels = Variable(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6LsBKjRJzbYz"
      },
      "outputs": [],
      "source": [
        "# copy data and model into GPU\n",
        "if args.cuda:\n",
        "    model = model.cuda()\n",
        "    features = features.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "    ori_labels = ori_labels.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-NVK1KSZ_Sc4"
      },
      "outputs": [],
      "source": [
        "# create train, validation and test batches\n",
        "train_batches = iterate_return(idx_train, args.sampleSize, labels, adj, 256)\n",
        "val_batches   = iterate_return(idx_val, args.sampleSize, labels, adj, 256)\n",
        "test_batches  = sample_test_batch(idx_test, args.sampleSize,adj, args.testBatchSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gK_H9m3Tzg9m"
      },
      "outputs": [],
      "source": [
        "#train_batches = iterate_return_fun(idx_train, args.sampleSize, labels, adj, 32 )\n",
        "\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    batch = 0; loss_train_sum= 0; accu_train_sum = 0;loss_val_sum= 0; accu_val_sum = 0\n",
        "    _idx_val, _idx_neighbor_val, _idx_neighbor2_val, _targets_val = val_batches[0]\n",
        "    for epoch_cnt,i in enumerate(train_batches):\n",
        "        _idx_train, _idx_neighbor_train, _idx_neighbor2_train, _targets_train = i\n",
        "        output = model(torch.index_select(features,0,_idx_train),torch.index_select(features,0,_idx_neighbor_train),torch.index_select(features,0,_idx_neighbor2_train))      \n",
        "        loss_train = criterion(output, _targets_train.type(torch.cuda.FloatTensor))\n",
        "        acc_train = accuracy(output, _targets_train.type(torch.cuda.FloatTensor))\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        loss_train_sum += loss_train.item()\n",
        "        accu_train_sum += acc_train.item()\n",
        "        batch += 1\n",
        "\n",
        "    if not args.fastmode:\n",
        "        model.eval()\n",
        "        output = model(torch.index_select(features,0,_idx_val),torch.index_select(features,0,_idx_neighbor_val),torch.index_select(features,0,_idx_neighbor2_val))\n",
        "        loss_val = criterion(output, _targets_val.type(torch.cuda.FloatTensor))\n",
        "        acc_val = accuracy(output, _targets_val.type(torch.cuda.FloatTensor))\n",
        "        loss_val_sum += loss_val.item()\n",
        "        accu_val_sum += acc_val.item()\n",
        "\n",
        "    if (epoch +1)%10 ==0:\n",
        "        test(epoch,test_batches)\n",
        "\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "              'loss_train: {:.4f}'.format(loss_train_sum/float(batch)),\n",
        "              'acc_train: {:.4f}'.format(accu_train_sum/float(batch)),\n",
        "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    if args.cuda == True:\n",
        "        return epoch+1, loss_train_sum/float(batch), loss_val.item(), accu_train_sum/float(batch), acc_val.item()\n",
        "    else:\n",
        "        return epoch+1, loss_train.data.numpy(), loss_val.data.numpy(), acc_train.data.numpy(), acc_val.data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "38cMQCoizlOp"
      },
      "outputs": [],
      "source": [
        "def test(epoch,test_batches):\n",
        "    model.eval()\n",
        "    batch = 0; loss_test_sum= 0; accu_test_sum = 0;f1_score_sum= 0; auc_sum = 0\n",
        "    for i in test_batches:\n",
        "        _idx_test, _idx_neighbor_test,_idx_neighbor2_test,targets  = i\n",
        "        output = model(torch.index_select(features,0,_idx_test),torch.index_select(features,0,_idx_neighbor_test),torch.index_select(features,0,_idx_neighbor2_test))        \n",
        "        loss_test = criterion(output, torch.index_select(ori_labels,0,targets))\n",
        "        acc_test = accuracy(output,torch.index_select(ori_labels,0,targets).type(torch.cuda.FloatTensor))\n",
        "        f1_score = score_f1(output,torch.index_select(ori_labels,0,targets).type(torch.cuda.FloatTensor))\n",
        "        try:\n",
        "            auc = roc_auc_score(torch.index_select(ori_labels,0,targets).cpu().data.numpy(),output.cpu().data.numpy())\n",
        "        except:\n",
        "            auc = 1\n",
        "\n",
        "        loss_test_sum += loss_test.item()\n",
        "        accu_test_sum += acc_test.item()\n",
        "        f1_score_sum += f1_score\n",
        "        auc_sum += auc\n",
        "        batch += 1\n",
        "\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test_sum/float(batch)),\n",
        "          \"accuracy= {:.4f}\".format(accu_test_sum/float(batch)),\n",
        "          \"f1_score = {:.4f}\".format(f1_score_sum/float(batch)),\n",
        "          \"auc = {:.4f}\".format(auc_sum/float(batch)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mhYwPN0vzq-K"
      },
      "outputs": [],
      "source": [
        "def link_prediction():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    accu = link_prediction_accuracy_2label(ori_adj, adj, output)\n",
        "    print ('link prediction accuracy is {}'.format(accu))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1lLe4KgYzxAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e310b3c-5dd9-4089-92fa-973acbfd0045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6958 acc_train: 0.4977 loss_val: 0.6934 acc_val: 0.4922 time: 2.4948s\n",
            "Epoch: 0002 loss_train: 0.6649 acc_train: 0.5370 loss_val: 0.6280 acc_val: 0.6602 time: 1.3244s\n",
            "Epoch: 0003 loss_train: 0.5429 acc_train: 0.7346 loss_val: 0.5217 acc_val: 0.7188 time: 1.3176s\n",
            "Epoch: 0004 loss_train: 0.4792 acc_train: 0.7593 loss_val: 0.4892 acc_val: 0.7578 time: 1.3290s\n",
            "Epoch: 0005 loss_train: 0.4536 acc_train: 0.7658 loss_val: 0.4754 acc_val: 0.7617 time: 1.3235s\n",
            "Epoch: 0006 loss_train: 0.4451 acc_train: 0.7706 loss_val: 0.4675 acc_val: 0.7578 time: 1.3261s\n",
            "Epoch: 0007 loss_train: 0.4369 acc_train: 0.7769 loss_val: 0.4620 acc_val: 0.7539 time: 1.3234s\n",
            "Epoch: 0008 loss_train: 0.4320 acc_train: 0.7771 loss_val: 0.4594 acc_val: 0.7578 time: 1.3221s\n",
            "Epoch: 0009 loss_train: 0.4274 acc_train: 0.7812 loss_val: 0.4564 acc_val: 0.7656 time: 1.3632s\n",
            "Test set results: loss= 0.4232 accuracy= 0.7827 f1_score = 0.7827 auc = 0.8794\n",
            "Epoch: 0010 loss_train: 0.4245 acc_train: 0.7818 loss_val: 0.4546 acc_val: 0.7617 time: 1.7779s\n",
            "Epoch: 0011 loss_train: 0.4199 acc_train: 0.7858 loss_val: 0.4547 acc_val: 0.7656 time: 1.3304s\n",
            "Epoch: 0012 loss_train: 0.4203 acc_train: 0.7916 loss_val: 0.4533 acc_val: 0.7617 time: 1.3300s\n",
            "Epoch: 0013 loss_train: 0.4201 acc_train: 0.7857 loss_val: 0.4522 acc_val: 0.7617 time: 1.3307s\n",
            "Epoch: 0014 loss_train: 0.4172 acc_train: 0.7883 loss_val: 0.4498 acc_val: 0.7656 time: 1.3272s\n",
            "Epoch: 0015 loss_train: 0.4169 acc_train: 0.7904 loss_val: 0.4475 acc_val: 0.7656 time: 1.3276s\n",
            "Epoch: 0016 loss_train: 0.4128 acc_train: 0.7915 loss_val: 0.4497 acc_val: 0.7773 time: 1.3282s\n",
            "Epoch: 0017 loss_train: 0.4154 acc_train: 0.7924 loss_val: 0.4485 acc_val: 0.7773 time: 1.3358s\n",
            "Epoch: 0018 loss_train: 0.4141 acc_train: 0.7975 loss_val: 0.4475 acc_val: 0.7812 time: 1.3513s\n",
            "Epoch: 0019 loss_train: 0.4132 acc_train: 0.7977 loss_val: 0.4470 acc_val: 0.7812 time: 1.3678s\n",
            "Test set results: loss= 0.4182 accuracy= 0.7979 f1_score = 0.7979 auc = 0.8795\n",
            "Epoch: 0020 loss_train: 0.4074 acc_train: 0.8055 loss_val: 0.4435 acc_val: 0.7852 time: 1.8153s\n",
            "Epoch: 0021 loss_train: 0.4060 acc_train: 0.8105 loss_val: 0.4439 acc_val: 0.7812 time: 1.3389s\n",
            "Epoch: 0022 loss_train: 0.4076 acc_train: 0.8125 loss_val: 0.4408 acc_val: 0.7891 time: 1.3382s\n",
            "Epoch: 0023 loss_train: 0.4010 acc_train: 0.8182 loss_val: 0.4355 acc_val: 0.7812 time: 1.3398s\n",
            "Epoch: 0024 loss_train: 0.3984 acc_train: 0.8203 loss_val: 0.4322 acc_val: 0.7930 time: 1.3386s\n",
            "Epoch: 0025 loss_train: 0.3949 acc_train: 0.8214 loss_val: 0.4238 acc_val: 0.7930 time: 1.3402s\n",
            "Epoch: 0026 loss_train: 0.3904 acc_train: 0.8260 loss_val: 0.4170 acc_val: 0.8008 time: 1.3548s\n",
            "Epoch: 0027 loss_train: 0.3826 acc_train: 0.8244 loss_val: 0.4066 acc_val: 0.8047 time: 1.3626s\n",
            "Epoch: 0028 loss_train: 0.3798 acc_train: 0.8292 loss_val: 0.4002 acc_val: 0.8164 time: 1.3574s\n",
            "Epoch: 0029 loss_train: 0.3701 acc_train: 0.8357 loss_val: 0.3946 acc_val: 0.8203 time: 1.3468s\n",
            "Test set results: loss= 0.3882 accuracy= 0.8291 f1_score = 0.8291 auc = 0.8990\n",
            "Epoch: 0030 loss_train: 0.3666 acc_train: 0.8342 loss_val: 0.3900 acc_val: 0.8281 time: 1.8009s\n",
            "Epoch: 0031 loss_train: 0.3651 acc_train: 0.8377 loss_val: 0.3854 acc_val: 0.8281 time: 1.3559s\n",
            "Epoch: 0032 loss_train: 0.3599 acc_train: 0.8376 loss_val: 0.3824 acc_val: 0.8320 time: 1.3533s\n",
            "Epoch: 0033 loss_train: 0.3601 acc_train: 0.8402 loss_val: 0.3808 acc_val: 0.8320 time: 1.3514s\n",
            "Epoch: 0034 loss_train: 0.3586 acc_train: 0.8448 loss_val: 0.3784 acc_val: 0.8359 time: 1.3499s\n",
            "Epoch: 0035 loss_train: 0.3547 acc_train: 0.8440 loss_val: 0.3779 acc_val: 0.8281 time: 1.3716s\n",
            "Epoch: 0036 loss_train: 0.3525 acc_train: 0.8483 loss_val: 0.3760 acc_val: 0.8359 time: 1.3737s\n",
            "Epoch: 0037 loss_train: 0.3546 acc_train: 0.8451 loss_val: 0.3743 acc_val: 0.8320 time: 1.3490s\n",
            "Epoch: 0038 loss_train: 0.3512 acc_train: 0.8466 loss_val: 0.3704 acc_val: 0.8359 time: 1.3478s\n",
            "Epoch: 0039 loss_train: 0.3490 acc_train: 0.8528 loss_val: 0.3697 acc_val: 0.8398 time: 1.3478s\n",
            "Test set results: loss= 0.3795 accuracy= 0.8340 f1_score = 0.8340 auc = 0.9056\n",
            "Epoch: 0040 loss_train: 0.3471 acc_train: 0.8497 loss_val: 0.3686 acc_val: 0.8320 time: 1.7916s\n",
            "Epoch: 0041 loss_train: 0.3453 acc_train: 0.8499 loss_val: 0.3659 acc_val: 0.8320 time: 1.3503s\n",
            "Epoch: 0042 loss_train: 0.3429 acc_train: 0.8501 loss_val: 0.3632 acc_val: 0.8320 time: 1.3448s\n",
            "Epoch: 0043 loss_train: 0.3404 acc_train: 0.8551 loss_val: 0.3625 acc_val: 0.8320 time: 1.3442s\n",
            "Epoch: 0044 loss_train: 0.3421 acc_train: 0.8513 loss_val: 0.3608 acc_val: 0.8438 time: 1.3557s\n",
            "Epoch: 0045 loss_train: 0.3393 acc_train: 0.8517 loss_val: 0.3593 acc_val: 0.8438 time: 1.3534s\n",
            "Epoch: 0046 loss_train: 0.3397 acc_train: 0.8521 loss_val: 0.3598 acc_val: 0.8359 time: 1.3414s\n",
            "Epoch: 0047 loss_train: 0.3341 acc_train: 0.8560 loss_val: 0.3568 acc_val: 0.8281 time: 1.3380s\n",
            "Epoch: 0048 loss_train: 0.3357 acc_train: 0.8534 loss_val: 0.3553 acc_val: 0.8359 time: 1.3376s\n",
            "Epoch: 0049 loss_train: 0.3323 acc_train: 0.8560 loss_val: 0.3525 acc_val: 0.8477 time: 1.3442s\n",
            "Test set results: loss= 0.3725 accuracy= 0.8364 f1_score = 0.8364 auc = 0.9113\n",
            "Epoch: 0050 loss_train: 0.3315 acc_train: 0.8548 loss_val: 0.3483 acc_val: 0.8438 time: 1.7776s\n",
            "Epoch: 0051 loss_train: 0.3307 acc_train: 0.8563 loss_val: 0.3461 acc_val: 0.8477 time: 1.4256s\n",
            "Epoch: 0052 loss_train: 0.3268 acc_train: 0.8613 loss_val: 0.3452 acc_val: 0.8398 time: 1.3925s\n",
            "Epoch: 0053 loss_train: 0.3274 acc_train: 0.8595 loss_val: 0.3422 acc_val: 0.8516 time: 1.3536s\n",
            "Epoch: 0054 loss_train: 0.3227 acc_train: 0.8615 loss_val: 0.3408 acc_val: 0.8477 time: 1.3450s\n",
            "Epoch: 0055 loss_train: 0.3217 acc_train: 0.8615 loss_val: 0.3371 acc_val: 0.8477 time: 1.3353s\n",
            "Epoch: 0056 loss_train: 0.3203 acc_train: 0.8586 loss_val: 0.3368 acc_val: 0.8516 time: 1.3363s\n",
            "Epoch: 0057 loss_train: 0.3154 acc_train: 0.8700 loss_val: 0.3340 acc_val: 0.8555 time: 1.3337s\n",
            "Epoch: 0058 loss_train: 0.3180 acc_train: 0.8621 loss_val: 0.3336 acc_val: 0.8555 time: 1.3362s\n",
            "Epoch: 0059 loss_train: 0.3144 acc_train: 0.8711 loss_val: 0.3330 acc_val: 0.8633 time: 1.3353s\n",
            "Test set results: loss= 0.3706 accuracy= 0.8457 f1_score = 0.8457 auc = 0.9127\n",
            "Epoch: 0060 loss_train: 0.3145 acc_train: 0.8672 loss_val: 0.3294 acc_val: 0.8633 time: 1.7711s\n",
            "Epoch: 0061 loss_train: 0.3103 acc_train: 0.8665 loss_val: 0.3305 acc_val: 0.8594 time: 1.3500s\n",
            "Epoch: 0062 loss_train: 0.3073 acc_train: 0.8711 loss_val: 0.3302 acc_val: 0.8672 time: 1.3568s\n",
            "Epoch: 0063 loss_train: 0.3071 acc_train: 0.8720 loss_val: 0.3288 acc_val: 0.8711 time: 1.3431s\n",
            "Epoch: 0064 loss_train: 0.3079 acc_train: 0.8697 loss_val: 0.3292 acc_val: 0.8633 time: 1.3344s\n",
            "Epoch: 0065 loss_train: 0.3082 acc_train: 0.8711 loss_val: 0.3282 acc_val: 0.8711 time: 1.3350s\n",
            "Epoch: 0066 loss_train: 0.3027 acc_train: 0.8710 loss_val: 0.3268 acc_val: 0.8711 time: 1.3358s\n",
            "Epoch: 0067 loss_train: 0.3030 acc_train: 0.8723 loss_val: 0.3262 acc_val: 0.8555 time: 1.3326s\n",
            "Epoch: 0068 loss_train: 0.3009 acc_train: 0.8758 loss_val: 0.3244 acc_val: 0.8633 time: 1.3345s\n",
            "Epoch: 0069 loss_train: 0.3033 acc_train: 0.8723 loss_val: 0.3237 acc_val: 0.8594 time: 1.3356s\n",
            "Test set results: loss= 0.3644 accuracy= 0.8403 f1_score = 0.8403 auc = 0.9169\n",
            "Epoch: 0070 loss_train: 0.3066 acc_train: 0.8680 loss_val: 0.3253 acc_val: 0.8594 time: 1.9357s\n",
            "Epoch: 0071 loss_train: 0.2984 acc_train: 0.8777 loss_val: 0.3246 acc_val: 0.8711 time: 1.3605s\n",
            "Epoch: 0072 loss_train: 0.3052 acc_train: 0.8726 loss_val: 0.3259 acc_val: 0.8750 time: 1.3353s\n",
            "Epoch: 0073 loss_train: 0.2997 acc_train: 0.8759 loss_val: 0.3281 acc_val: 0.8711 time: 1.3448s\n",
            "Epoch: 0074 loss_train: 0.2989 acc_train: 0.8728 loss_val: 0.3248 acc_val: 0.8672 time: 1.3390s\n",
            "Epoch: 0075 loss_train: 0.3001 acc_train: 0.8758 loss_val: 0.3284 acc_val: 0.8750 time: 1.3369s\n",
            "Epoch: 0076 loss_train: 0.2961 acc_train: 0.8765 loss_val: 0.3238 acc_val: 0.8711 time: 1.3354s\n",
            "Epoch: 0077 loss_train: 0.2969 acc_train: 0.8768 loss_val: 0.3243 acc_val: 0.8672 time: 1.3373s\n",
            "Epoch: 0078 loss_train: 0.2953 acc_train: 0.8784 loss_val: 0.3230 acc_val: 0.8672 time: 1.3380s\n",
            "Epoch: 0079 loss_train: 0.2928 acc_train: 0.8755 loss_val: 0.3280 acc_val: 0.8750 time: 1.3469s\n",
            "Test set results: loss= 0.3695 accuracy= 0.8354 f1_score = 0.8354 auc = 0.9164\n",
            "Epoch: 0080 loss_train: 0.2955 acc_train: 0.8793 loss_val: 0.3267 acc_val: 0.8711 time: 1.8295s\n",
            "Epoch: 0081 loss_train: 0.2907 acc_train: 0.8780 loss_val: 0.3266 acc_val: 0.8750 time: 1.3406s\n",
            "Epoch: 0082 loss_train: 0.2926 acc_train: 0.8788 loss_val: 0.3283 acc_val: 0.8789 time: 1.3424s\n",
            "Epoch: 0083 loss_train: 0.2944 acc_train: 0.8770 loss_val: 0.3263 acc_val: 0.8711 time: 1.3424s\n",
            "Epoch: 0084 loss_train: 0.2932 acc_train: 0.8804 loss_val: 0.3215 acc_val: 0.8750 time: 1.3423s\n",
            "Epoch: 0085 loss_train: 0.2908 acc_train: 0.8777 loss_val: 0.3218 acc_val: 0.8789 time: 1.3430s\n",
            "Epoch: 0086 loss_train: 0.2898 acc_train: 0.8816 loss_val: 0.3222 acc_val: 0.8789 time: 1.3429s\n",
            "Epoch: 0087 loss_train: 0.2907 acc_train: 0.8770 loss_val: 0.3230 acc_val: 0.8672 time: 1.3398s\n",
            "Epoch: 0088 loss_train: 0.2920 acc_train: 0.8781 loss_val: 0.3242 acc_val: 0.8711 time: 1.3545s\n",
            "Epoch: 0089 loss_train: 0.2891 acc_train: 0.8808 loss_val: 0.3233 acc_val: 0.8711 time: 1.3523s\n",
            "Test set results: loss= 0.3680 accuracy= 0.8369 f1_score = 0.8369 auc = 0.9167\n",
            "Epoch: 0090 loss_train: 0.2909 acc_train: 0.8773 loss_val: 0.3247 acc_val: 0.8711 time: 1.7728s\n",
            "Epoch: 0091 loss_train: 0.2863 acc_train: 0.8828 loss_val: 0.3251 acc_val: 0.8750 time: 1.3461s\n",
            "Epoch: 0092 loss_train: 0.2879 acc_train: 0.8800 loss_val: 0.3269 acc_val: 0.8750 time: 1.3444s\n",
            "Epoch: 0093 loss_train: 0.2892 acc_train: 0.8780 loss_val: 0.3244 acc_val: 0.8789 time: 1.3389s\n",
            "Epoch: 0094 loss_train: 0.2865 acc_train: 0.8798 loss_val: 0.3253 acc_val: 0.8711 time: 1.3417s\n",
            "Epoch: 0095 loss_train: 0.2858 acc_train: 0.8828 loss_val: 0.3253 acc_val: 0.8750 time: 1.3449s\n",
            "Epoch: 0096 loss_train: 0.2878 acc_train: 0.8803 loss_val: 0.3235 acc_val: 0.8672 time: 1.3449s\n",
            "Epoch: 0097 loss_train: 0.2852 acc_train: 0.8801 loss_val: 0.3234 acc_val: 0.8711 time: 1.3546s\n",
            "Epoch: 0098 loss_train: 0.2857 acc_train: 0.8813 loss_val: 0.3240 acc_val: 0.8633 time: 1.3501s\n",
            "Epoch: 0099 loss_train: 0.2856 acc_train: 0.8828 loss_val: 0.3226 acc_val: 0.8672 time: 1.3387s\n",
            "Test set results: loss= 0.3684 accuracy= 0.8428 f1_score = 0.8428 auc = 0.9175\n",
            "Epoch: 0100 loss_train: 0.2840 acc_train: 0.8817 loss_val: 0.3219 acc_val: 0.8750 time: 1.7646s\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "t_total = time.time()\n",
        "loss_values = []\n",
        "bad_counter = 0\n",
        "best = args.epochs + 1\n",
        "best_epoch = 0\n",
        "for epoch in range(args.epochs):  # args.epochs\n",
        "    epoch, loss_train, loss_val, acc_train, acc_val = train(epoch)\n",
        "    loss_values.append(loss_val)\n",
        "    torch.save(model.state_dict(), '{}.pkl'.format(epoch))\n",
        "    torch.save(model, '{}.modelPkl'.format(epoch))\n",
        "    if loss_values[-1] < best:\n",
        "        best = loss_values[-1]\n",
        "        best_epoch = epoch\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "\n",
        "    if bad_counter == args.patience:\n",
        "        break\n",
        "\n",
        "    files = glob.glob('/content/Patience/*.pkl')\n",
        "    for file in files:\n",
        "        epoch_nb = int(file.split('.')[0])\n",
        "        if epoch_nb < best_epoch:\n",
        "            os.remove(file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LE50T0qB0AgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e2a5c7-8106-43b3-c545-0887a5b6846c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization Finished!\n",
            "Total time elapsed: 431.8297s\n",
            "Loading 84th epoch\n",
            "Test set results: loss= 0.3651 accuracy= 0.8452 f1_score = 0.8452 auc = 0.9175\n"
          ]
        }
      ],
      "source": [
        "files = glob.glob('content/Patience/*.pkl')\n",
        "for file in files:\n",
        "    epoch_nb = int(file.split('.')[0])\n",
        "    if epoch_nb > best_epoch:\n",
        "        os.remove(file)\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "# Restore best model\n",
        "print('Loading {}th epoch'.format(best_epoch))\n",
        "model.load_state_dict(torch.load('{}.pkl'.format(best_epoch)))\n",
        "model_dict = model.state_dict()\n",
        "test(epoch,test_batches)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}